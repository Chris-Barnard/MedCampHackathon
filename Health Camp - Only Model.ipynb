{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamad\\Documents\\GitHub\\MedCampHackathon\\data\n"
     ]
    }
   ],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in data sources\n",
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTestData():\n",
    "    test_data = pd.read_csv('Test.csv',sep=',', parse_dates=[2], index_col=['Patient_ID', 'Health_Camp_ID'])\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTrainData():\n",
    "    train_data = pd.read_csv('Train/Train.csv',sep=',', parse_dates=[2], index_col=['Patient_ID', 'Health_Camp_ID'])\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in some other key fields\n",
    "### Define a function that will merge in all other fields into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getData(sourceData):\n",
    "    HC1 = pd.read_csv('Train/First_Health_Camp_Attended.csv', sep=',', index_col=['Patient_ID', 'Health_Camp_ID'])\n",
    "    HC1.pop('Unnamed: 4')\n",
    "    sourceData['Health_Camp_Score_1'] = HC1['Health_Score']\n",
    "    sourceData['Health_Camp_Attended_1'] = sourceData['Health_Camp_Score_1'].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "    HC2 = pd.read_csv('Train/Second_Health_Camp_Attended.csv', sep=',', index_col=['Patient_ID','Health_Camp_ID'])\n",
    "    sourceData['Health_Camp_Score_2'] = HC2['Health Score']\n",
    "    sourceData['Health_Camp_Attended_2'] = sourceData['Health_Camp_Score_2'].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "    HC3 = pd.read_csv('Train/Third_Health_Camp_Attended.csv', sep=',', index_col=['Patient_ID','Health_Camp_ID'])\n",
    "    sourceData['Health_Camp_Stalls_3'] = HC3['Number_of_stall_visited']\n",
    "    sourceData['Health_Camp_Attended_3'] = sourceData['Health_Camp_Stalls_3'].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "    ### Positive_Result\n",
    "\n",
    "    sourceData['Positive_Result'] = (sourceData['Health_Camp_Attended_1'] | sourceData['Health_Camp_Attended_2'] | sourceData['Health_Camp_Attended_3'])\n",
    "\n",
    "    ### Health_Camp_Details\n",
    "\n",
    "    HCDetails = pd.read_csv('Train/Health_Camp_Detail.csv', sep=',', index_col='Health_Camp_ID', parse_dates=[1,2])\n",
    "    sourceData = sourceData.join(HCDetails)\n",
    "\n",
    "    ### Patient Details\n",
    "\n",
    "    PatientProfiles = pd.read_csv('Train/Patient_Profile.csv', sep=',', index_col='Patient_ID', parse_dates=[8])\n",
    "    sourceData = sourceData.join(PatientProfiles)\n",
    "\n",
    "    ### Add in the reg_num\n",
    "\n",
    "    df = sourceData[['Registration_Date','Positive_Result']]\n",
    "    df.reset_index(level=['Patient_ID','Health_Camp_ID'], inplace=1)\n",
    "    hist = df.sort_values(by=['Patient_ID','Registration_Date'])\n",
    "    hist.set_index(['Patient_ID','Health_Camp_ID'], inplace=1)\n",
    "\n",
    "    sourceData['reg_num'] = hist.groupby(level=0).cumcount()\n",
    "    \n",
    "    ### Repeat Register Flag\n",
    "    sourceData['rep_reg'] = sourceData['reg_num'].apply(lambda x: True if x > 0 else False)\n",
    "    \n",
    "    ### rep_reg_bin\n",
    "\n",
    "    # define a bin size\n",
    "    size = 8\n",
    "    bins = np.logspace(np.log2(0.99), np.log2(sourceData.reg_num.max()), size, endpoint=True, base=2)\n",
    "\n",
    "    sourceData['rep_reg_bin'] = pd.cut(sourceData.reg_num, bins).cat.rename_categories([1,2,3,4,5,6,7])\n",
    "    sourceData['rep_reg_bin'] = sourceData['rep_reg_bin'].cat.add_categories(-1)\n",
    "    sourceData['rep_reg_bin'] = sourceData['rep_reg_bin'].fillna(-1)\n",
    "    \n",
    "    #train_data['rep_reg_bin'] = train_data['rep_reg_bin'].cat.rename_categories([1,2,3,4,5,6,7])\n",
    "    \n",
    "    ### has_var\n",
    "    sourceData['has_var'] = (sourceData['Var1'] > 0) | (sourceData['Var2'] > 0) | (sourceData['Var3'] > 0) | (sourceData['Var4'] > 0) | (sourceData['Var5'] > 0) \n",
    "    \n",
    "    ### v1_b\n",
    "    # define a bin size\n",
    "    #size = 5\n",
    "    #bins = np.logspace(np.log2(.99), np.log2(sourceData.Var1.max()), size, endpoint=True, base=2)\n",
    "\n",
    "    #sourceData['v1_b'] = pd.cut(sourceData.Var1, bins).cat.rename_categories([1,2,3,4])\n",
    "    #sourceData['v1_b'] = sourceData['v1_b'].cat.add_categories(-1)\n",
    "    #sourceData['v1_b'] = sourceData['v1_b'].fillna(-1)\n",
    "    \n",
    "    ### online   \n",
    "    sourceData['online'] = (sourceData['Online_Follower']) | (sourceData['LinkedIn_Shared']) | (sourceData['Twitter_Shared']) | (sourceData['Facebook_Shared'])\n",
    "    \n",
    "    ### City_Type\n",
    "    sourceData['City_Type'] = sourceData['City_Type'].fillna('Z')\n",
    "    \n",
    "    ### Age\n",
    "    val_counts = sourceData['Age'].value_counts().to_dict()\n",
    "    #mode_age = sourceData['Age'].mode()\n",
    "    for key, value in val_counts.items():\n",
    "        if key == 'None':\n",
    "            val_counts[key] = None\n",
    "        else:\n",
    "            val_counts[key] = int(key)\n",
    "    val_counts\n",
    "    sourceData['Age'] = sourceData['Age'].apply(lambda x: val_counts.get(x))\n",
    "    sourceData['Age'] = sourceData['Age'].fillna(41)\n",
    "    \n",
    "    ### Education_Score\n",
    "    val_counts = sourceData['Education_Score'].value_counts().to_dict()\n",
    "    for key, value in val_counts.items():\n",
    "        if key == 'None':\n",
    "            val_counts[key] = None\n",
    "        else:\n",
    "            val_counts[key] = float(key)\n",
    "    val_counts\n",
    "    sourceData['Education_Score'] = sourceData['Education_Score'].apply(lambda x: val_counts.get(x))\n",
    "    \n",
    "    ### Employer_Category\n",
    "    sourceData['Employer_Category'] = sourceData['Employer_Category'].fillna('None Provided')\n",
    "    \n",
    "    ### Time Since First Interaction\n",
    "    sourceData['DaysSeen'] = sourceData.Registration_Date - sourceData.First_Interaction\n",
    "\n",
    "    ### DaysSeen\n",
    "    sourceData.DaysSeen = sourceData[sourceData.DaysSeen.notnull()].DaysSeen.apply(lambda x: x.days)\n",
    "    sourceData.DaysSeen = sourceData.DaysSeen.fillna(0)\n",
    "\n",
    "    \n",
    "    return sourceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = getData(loadTrainData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### var1-5 train_data\n",
    "vars = ['Var3','Var4','Var5','Var1','Var2','Age','reg_num','DaysSeen']\n",
    "scaler = {}\n",
    "\n",
    "\n",
    "# bin data and store scale to apply to test_data\n",
    "### v1_b\n",
    "# define a bin size\n",
    "size = 5\n",
    "scaler['v1_b'] = np.logspace(np.log2(.99), np.log2(train_data.Var1.max()), size, endpoint=True, base=2)\n",
    "train_data['v1_b'] = pd.cut(train_data.Var1, scaler['v1_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['v1_b'] = train_data['v1_b'].cat.add_categories(-1)\n",
    "train_data['v1_b'] = train_data['v1_b'].fillna(-1)\n",
    "\n",
    "### v2_b\n",
    "# define a bin size\n",
    "size = 5\n",
    "scaler['v2_b'] = np.logspace(np.log2(.99), np.log2(train_data.Var2.max()), size, endpoint=True, base=2)\n",
    "train_data['v2_b'] = pd.cut(train_data.Var2, scaler['v2_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['v2_b'] = train_data['v2_b'].cat.add_categories(-1)\n",
    "train_data['v2_b'] = train_data['v2_b'].fillna(-1)\n",
    "\n",
    "### age_b\n",
    "size = 5\n",
    "scaler['age_b'] = np.linspace(0,train_data.Age.max(), size, endpoint=True)\n",
    "\n",
    "train_data['age_b'] = pd.cut(train_data.Age, scaler['age_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['age_b'] = train_data['age_b'].cat.add_categories(-1)\n",
    "train_data['age_b'] = train_data['age_b'].fillna(-1)\n",
    "\n",
    "### educ_b\n",
    "size = 5\n",
    "scaler['educ_b'] = np.linspace(0,train_data.Education_Score.max(), size, endpoint=True)\n",
    "\n",
    "train_data['educ_b'] = pd.cut(train_data.Age, scaler['educ_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['educ_b'] = train_data['educ_b'].cat.add_categories(-1)\n",
    "train_data['educ_b'] = train_data['educ_b'].fillna(-1)\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "\n",
    "for var in vars:\n",
    "    scaler[var] = scale.fit(train_data[var])\n",
    "    #x_minmax = scale.fit(train_data[var])\n",
    "    #print(x_minmax)\n",
    "    \n",
    "    train_data[var] = scaler[var].transform(train_data[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data = getData(loadTestData())\n",
    "drops = ['Health_Camp_Score_1','Health_Camp_Attended_1','Health_Camp_Score_2','Health_Camp_Attended_2','Health_Camp_Stalls_3','Health_Camp_Attended_3','Positive_Result']\n",
    "for col in drops:\n",
    "    test_data.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Conda\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "### var1-5 test_data\n",
    "\n",
    "test_data['v1_b'] = pd.cut(test_data.Var1, scaler['v1_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['v1_b'] = test_data['v1_b'].cat.add_categories(-1)\n",
    "test_data['v1_b'] = test_data['v1_b'].fillna(-1)\n",
    "\n",
    "test_data['v2_b'] = pd.cut(test_data.Var2, scaler['v2_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['v2_b'] = test_data['v2_b'].cat.add_categories(-1)\n",
    "test_data['v2_b'] = test_data['v2_b'].fillna(-1)\n",
    "\n",
    "test_data['age_b'] = pd.cut(test_data.Age, scaler['age_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['age_b'] = test_data['age_b'].cat.add_categories(-1)\n",
    "test_data['age_b'] = test_data['age_b'].fillna(-1)\n",
    "\n",
    "test_data['educ_b'] = pd.cut(test_data.Age, scaler['educ_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['educ_b'] = test_data['educ_b'].cat.add_categories(-1)\n",
    "test_data['educ_b'] = test_data['educ_b'].fillna(-1)\n",
    "\n",
    "for var in vars:\n",
    "    test_data[var] = scaler[var].transform(test_data[var].reshape(-1,1)).reshape(1,-1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in main model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import models from scikit learn module:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import metrics\n",
    "\n",
    "#Generic function for making a classification model and accessing performance:\n",
    "def classification_model(model, data, predictors, outcome):\n",
    "    #Fit the model\n",
    "    model.fit(data[predictors],data[outcome])\n",
    "    \n",
    "    #Make predictions on training set:\n",
    "    predictions = model.predict(data[predictors])\n",
    "  \n",
    "    #Print accuracy\n",
    "    accuracy = metrics.accuracy_score(predictions,data[outcome])\n",
    "    print (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "    \n",
    "    # Record auc score\n",
    "    auc = metrics.roc_auc_score(data[outcome], predictions)\n",
    "    \n",
    "    print (\"ROC AUC Score : %s\" % \"{0:.3%}\".format(auc))\n",
    "\n",
    "    #Perform k-fold cross-validation with 5 folds\n",
    "    kf = KFold(data.shape[0], n_folds=5)\n",
    "    error = []\n",
    "    for train, test in kf:\n",
    "        # Filter training data\n",
    "        train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "        # The target we're using to train the algorithm.\n",
    "        train_target = data[outcome].iloc[train]\n",
    "    \n",
    "        # Training the algorithm using the predictors and target.\n",
    "        model.fit(train_predictors, train_target)\n",
    "    \n",
    "        #Record error from each cross-validation run\n",
    "        error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    " \n",
    "    print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "    #Fit the model again so that it can be refered outside the function:\n",
    "    model.fit(data[predictors],data[outcome])\n",
    "    \n",
    "    # return the roc_auc score to be stored\n",
    "    return model\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['Category1','Category2','Category3','rep_reg_bin','City_Type','age_b','educ_b','v1_b','v2_b','Employer_Category']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    train_data[i] = le.fit_transform(train_data[i])\n",
    "    #scaler[i] = scale.fit(train_data[i])\n",
    "    #train_data[i] = scaler[i].transform(train_data[i])\n",
    "#train_data.dtypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in var_mod:\n",
    "    test_data[i] = le.fit_transform(test_data[i])\n",
    "    #test_data[i] = scaler[i].transform(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Registration_Date</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Health_Camp_Score_1</th>\n",
       "      <th>Health_Camp_Attended_1</th>\n",
       "      <th>Health_Camp_Score_2</th>\n",
       "      <th>Health_Camp_Attended_2</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>rep_reg</th>\n",
       "      <th>rep_reg_bin</th>\n",
       "      <th>has_var</th>\n",
       "      <th>online</th>\n",
       "      <th>DaysSeen</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v2_b</th>\n",
       "      <th>age_b</th>\n",
       "      <th>educ_b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Health_Camp_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489652</th>\n",
       "      <th>6578</th>\n",
       "      <td>2005-09-10</td>\n",
       "      <td>0.420086</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>1.442928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.695679</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507246</th>\n",
       "      <th>6578</th>\n",
       "      <td>2005-08-18</td>\n",
       "      <td>5.795981</td>\n",
       "      <td>1.263127</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>5.561781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2.592913</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546566</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523729</th>\n",
       "      <th>6534</th>\n",
       "      <td>2006-04-29</td>\n",
       "      <td>-0.104391</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>-0.204613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.402054</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499368</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.772144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524931</th>\n",
       "      <th>6535</th>\n",
       "      <td>2004-02-07</td>\n",
       "      <td>-0.104391</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>-0.204613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696944</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521364</th>\n",
       "      <th>6529</th>\n",
       "      <td>2006-02-28</td>\n",
       "      <td>1.862400</td>\n",
       "      <td>0.201998</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>5.561781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845597</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4.088302</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2.857445</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Registration_Date      Var1      Var2      Var3  \\\n",
       "Patient_ID Health_Camp_ID                                                   \n",
       "489652     6578                  2005-09-10  0.420086 -0.063285 -0.019631   \n",
       "507246     6578                  2005-08-18  5.795981  1.263127 -0.019631   \n",
       "523729     6534                  2006-04-29 -0.104391 -0.063285 -0.019631   \n",
       "524931     6535                  2004-02-07 -0.104391 -0.063285 -0.019631   \n",
       "521364     6529                  2006-02-28  1.862400  0.201998 -0.019631   \n",
       "\n",
       "                              Var4      Var5  Health_Camp_Score_1  \\\n",
       "Patient_ID Health_Camp_ID                                           \n",
       "489652     6578           -0.11236  1.442928                  NaN   \n",
       "507246     6578           -0.11236  5.561781                  NaN   \n",
       "523729     6534           -0.11236 -0.204613                  NaN   \n",
       "524931     6535           -0.11236 -0.204613                  NaN   \n",
       "521364     6529           -0.11236  5.561781                  NaN   \n",
       "\n",
       "                          Health_Camp_Attended_1  Health_Camp_Score_2  \\\n",
       "Patient_ID Health_Camp_ID                                               \n",
       "489652     6578                            False                  NaN   \n",
       "507246     6578                            False                  NaN   \n",
       "523729     6534                            False             0.402054   \n",
       "524931     6535                            False                  NaN   \n",
       "521364     6529                            False             0.845597   \n",
       "\n",
       "                          Health_Camp_Attended_2   ...     reg_num rep_reg  \\\n",
       "Patient_ID Health_Camp_ID                          ...                       \n",
       "489652     6578                            False   ...    1.695679    True   \n",
       "507246     6578                            False   ...    2.592913    True   \n",
       "523729     6534                             True   ...    0.499368    True   \n",
       "524931     6535                            False   ...   -0.696944   False   \n",
       "521364     6529                             True   ...    4.088302    True   \n",
       "\n",
       "                          rep_reg_bin has_var online  DaysSeen  v1_b  v2_b  \\\n",
       "Patient_ID Health_Camp_ID                                                    \n",
       "489652     6578                     5    True      0  0.302927     1     0   \n",
       "507246     6578                     5    True      0  0.546566     3     2   \n",
       "523729     6534                     3   False      0  1.772144     0     0   \n",
       "524931     6535                     0   False      0 -0.723311     0     0   \n",
       "521364     6529                     6    True      1  2.857445     2     1   \n",
       "\n",
       "                           age_b  educ_b  \n",
       "Patient_ID Health_Camp_ID                 \n",
       "489652     6578                1       0  \n",
       "507246     6578                0       0  \n",
       "523729     6534                1       0  \n",
       "524931     6535                1       0  \n",
       "521364     6529                0       0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Registration_Date</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Camp_Start_Date</th>\n",
       "      <th>Camp_End_Date</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>rep_reg</th>\n",
       "      <th>rep_reg_bin</th>\n",
       "      <th>has_var</th>\n",
       "      <th>online</th>\n",
       "      <th>DaysSeen</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v2_b</th>\n",
       "      <th>age_b</th>\n",
       "      <th>educ_b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Health_Camp_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505701</th>\n",
       "      <th>6548</th>\n",
       "      <td>2006-05-21</td>\n",
       "      <td>-0.719619</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.715928</td>\n",
       "      <td>2006-06-13</td>\n",
       "      <td>2006-08-18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715928</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.710182</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500633</th>\n",
       "      <th>6584</th>\n",
       "      <td>2006-06-02</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-08-04</td>\n",
       "      <td>2006-08-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719619</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.262717</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506945</th>\n",
       "      <th>6582</th>\n",
       "      <td>2006-08-10</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-04-06</td>\n",
       "      <td>2007-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.712236</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497447</th>\n",
       "      <th>6551</th>\n",
       "      <td>2006-08-27</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-11-13</td>\n",
       "      <td>2006-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719619</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.715928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496446</th>\n",
       "      <th>6533</th>\n",
       "      <td>2006-09-19</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-09-20</td>\n",
       "      <td>2006-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Registration_Date      Var1      Var2      Var3  \\\n",
       "Patient_ID Health_Camp_ID                                                   \n",
       "505701     6548                  2006-05-21 -0.719619 -0.723311 -0.723311   \n",
       "500633     6584                  2006-06-02 -0.723311 -0.723311 -0.723311   \n",
       "506945     6582                  2006-08-10 -0.723311 -0.723311 -0.723311   \n",
       "497447     6551                  2006-08-27 -0.723311 -0.723311 -0.723311   \n",
       "496446     6533                  2006-09-19 -0.723311 -0.723311 -0.723311   \n",
       "\n",
       "                               Var4      Var5 Camp_Start_Date Camp_End_Date  \\\n",
       "Patient_ID Health_Camp_ID                                                     \n",
       "505701     6548           -0.723311 -0.715928      2006-06-13    2006-08-18   \n",
       "500633     6584           -0.723311 -0.723311      2006-08-04    2006-08-09   \n",
       "506945     6582           -0.723311 -0.723311      2006-04-06    2007-11-07   \n",
       "497447     6551           -0.723311 -0.723311      2006-11-13    2006-11-18   \n",
       "496446     6533           -0.723311 -0.723311      2006-09-20    2006-09-23   \n",
       "\n",
       "                           Category1  Category2   ...     reg_num  rep_reg  \\\n",
       "Patient_ID Health_Camp_ID                         ...                        \n",
       "505701     6548                    2          5   ...   -0.715928     True   \n",
       "500633     6584                    1          0   ...   -0.719619     True   \n",
       "506945     6582                    0          4   ...   -0.712236     True   \n",
       "497447     6551                    1          2   ...   -0.719619     True   \n",
       "496446     6533                    0          3   ...   -0.723311    False   \n",
       "\n",
       "                           rep_reg_bin  has_var  online  DaysSeen  v1_b  v2_b  \\\n",
       "Patient_ID Health_Camp_ID                                                       \n",
       "505701     6548                      2     True       0  3.710182     1     0   \n",
       "500633     6584                      1    False       1  1.262717     0     0   \n",
       "506945     6582                      3    False       0 -0.306171     0     0   \n",
       "497447     6551                      1    False       0 -0.715928     0     0   \n",
       "496446     6533                      0    False       0 -0.723311     0     0   \n",
       "\n",
       "                          age_b  educ_b  \n",
       "Patient_ID Health_Camp_ID                \n",
       "505701     6548               1       0  \n",
       "500633     6584               1       0  \n",
       "506945     6582               1       0  \n",
       "497447     6551               1       0  \n",
       "496446     6533               1       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the model that we want to use and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   26.3s finished\n"
     ]
    }
   ],
   "source": [
    "# I want to write a loop to test out a couple of different models and show the results\n",
    "# I need a variable to hold the scenarios to run - it will be a list of dicts describing each run\n",
    "outcome_var = 'Positive_Result'\n",
    "predictor_var1 = ['Category1','Category2','Category3','rep_reg_bin','City_Type','age_b','educ_b','online','v1_b','v2_b','Employer_Category']\n",
    "predictor_var2 = ['Category1','Category2','rep_reg_bin','City_Type','age_b','educ_b','online','v1_b','v2_b','has_var','Employer_Category']\n",
    "predictor_var3 = ['DaysSeen','Category1','Category2','Category3','reg_num','rep_reg','City_Type','Age','educ_b','online','has_var','Employer_Category']\n",
    "predictor_var4 = ['DaysSeen','Category1','Category2','Category3','rep_reg','reg_num','City_Type','Age','educ_b','online','Var1','Var2','Var3','Var4','Var5','Employer_Category']\n",
    "predictor_var5 = ['Category1','Category2','Category3','rep_reg','reg_num','City_Type','Age','educ_b','online','Var1','Var2','Var3','Var4','Var5','has_var','Employer_Category']\n",
    "predictor_var6 = ['DaysSeen','Category1','Category2','Category3','rep_reg','reg_num','City_Type','Age','educ_b','online','Var1','Var2','Var3','Var4','Var5','has_var','Employer_Category']\n",
    "scenarios = []\n",
    "scores = []\n",
    "\n",
    "# define scenarios I want to run\n",
    "\n",
    "### LinearSVC\n",
    "# Setup paramaters to search for this scenario\n",
    "c_values = list(np.logspace(np.log2(0.0001),np.log2(.05),25, base=2))\n",
    "penalty = ['l2']\n",
    "loss = ['squared_hinge']\n",
    "param_grid = dict(C=c_values, penalty=penalty, loss=loss)\n",
    "#scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var1, params=param_grid))\n",
    "#scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var2, params=param_grid))\n",
    "#scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var3, params=param_grid))\n",
    "#scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var4, params=param_grid))\n",
    "#scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var5, params=param_grid))\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var6, params=param_grid))\n",
    "\n",
    "### RBF SVC\n",
    "c_values = list(np.logspace(np.log2(0.01),np.log2(10),10, base=2))\n",
    "kernel= ['linear','poly','rbf','sigmoid']\n",
    "param_grid = dict(C=c_values)\n",
    "#scenarios.append(dict(model=SVC(), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "### LogisticRegression\n",
    "# Setup paramaters to search for this scenario\n",
    "c_values = list(np.logspace(np.log2(0.001),np.log2(.05),25, base=2))\n",
    "solver_options = ['newton-cg','lbfgs','sag','liblinear']\n",
    "param_grid = dict(C=c_values, solver=solver_options)\n",
    "#scenarios.append(dict(model=LogisticRegression(), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "### DecisionTree\n",
    "criterion = ['gini','entropy']\n",
    "max_features = [None, 1, 2, 4, 6]\n",
    "max_depth = [None, 4, 6, 8]\n",
    "param_grid = dict(criterion=criterion, max_features=max_features, max_depth=max_depth)\n",
    "#scenarios.append(dict(model=DecisionTreeClassifier(), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "### Random Forest\n",
    "param_grid = {}\n",
    "#scenarios.append(dict(model=RandomForestClassifier(n_estimators=100), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "# second run\n",
    "n_estimators = [10, 20, 35, 50, 75]\n",
    "max_depth = [None, 4, 8, 12]\n",
    "max_features = [None, 1, 2, 4]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "predictors = ['Category1', 'Category2', 'Employer_Category', 'rep_reg_bin', 'City_Type'] #top 5 inserted from below\n",
    "#scenarios.append(dict(model=RandomForestClassifier(n_estimators=25), predictors=predictors, params=param_grid))\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# iterate through them\n",
    "for scenario in scenarios:\n",
    "    #classification_model(scenario['model'], train_data, scenario['predictors'], outcome_var)\n",
    "    #score = metrics.roc_auc_score(train_data[outcome_var], scenario['model'].predict(train_data[scenario['predictors']]))\n",
    "\n",
    "    grid = GridSearchCV(scenario['model'], param_grid=scenario['params'], cv=None, scoring='roc_auc', verbose=1, n_jobs=4)\n",
    "    grid.fit(train_data[scenario['predictors']],train_data.Positive_Result)\n",
    "    scenario['model'] = grid.best_estimator_\n",
    "    predictions = scenario['model'].predict(train_data[scenario['predictors']])\n",
    "    score = metrics.roc_auc_score(train_data.Positive_Result, predictions)\n",
    "    scores.append(score)\n",
    "\n",
    "### Include a final run of \n",
    "# Grab Feature Importance Table\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6714906172589209]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select model with the best auc score\n",
    "best_scenario = scores.index(max(scores))\n",
    "scenarios[best_scenario]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DaysSeen',\n",
       " 'Category1',\n",
       " 'Category2',\n",
       " 'Category3',\n",
       " 'rep_reg',\n",
       " 'reg_num',\n",
       " 'City_Type',\n",
       " 'Age',\n",
       " 'educ_b',\n",
       " 'online',\n",
       " 'Var1',\n",
       " 'Var2',\n",
       " 'Var3',\n",
       " 'Var4',\n",
       " 'Var5',\n",
       " 'has_var',\n",
       " 'Employer_Category']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios[best_scenario]['predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 76.640%\n",
      "ROC AUC Score : 67.149%\n",
      "Cross-Validation Score : 76.643%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.010573712634405636, class_weight=None, dual=False,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1500, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=1e-06, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the parameters we want to run\n",
    "#scenarios[best_scenario]['model'].set_params(**grid.best_params_)\n",
    "    \n",
    "\n",
    "# Run the model\n",
    "classification_model(scenarios[best_scenario]['model'], train_data, scenarios[best_scenario]['predictors'], outcome_var)\n",
    "\n",
    "# Save the predicted labels to the dataset\n",
    "train_data['predicted'] = scenarios[best_scenario]['model'].predict(train_data[scenarios[best_scenario]['predictors']])\n",
    "\n",
    "# Output the model used\n",
    "scenarios[best_scenario]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Version for LinearSVC\n",
    "clf = CalibratedClassifierCV(scenarios[best_scenario]['model'])\n",
    "clf.fit(train_data[scenarios[best_scenario]['predictors']],train_data[outcome_var])\n",
    "results = clf.predict_proba(test_data[scenarios[best_scenario]['predictors']])\n",
    "formatted = list()\n",
    "for pFalse,pTrue  in results:\n",
    "    formatted.append(pTrue)\n",
    "\n",
    "outcome = pd.Series(formatted, index=test_data.index)\n",
    "\n",
    "test_data['Outcome'] = outcome\n",
    "test_data['Outcome'].to_csv('output.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into results\n",
    "## What values do we miss on the training sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.727224\n",
       "Name: Positive_Result, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null accuracy for the problem\n",
    "train_data.Positive_Result.value_counts().head(1) / len(train_data.Positive_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive_Result</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>48193</td>\n",
       "      <td>6551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>11034</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted        False  True \n",
       "Positive_Result              \n",
       "False            48193   6551\n",
       "True             11034   9500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "train_data.groupby(['predicted','Positive_Result']).size().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(train_data.Positive_Result, train_data.predicted)\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy - *How often is the classifier correct?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766399213582\n",
      "0.766399213582\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / (FP + FN + TP + TN))\n",
    "print(metrics.accuracy_score(train_data.Positive_Result, train_data.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity - *When the actual value is positive, how often is the prediction correct?*\n",
    " * How 'sensitive' or selective is the model with detecting a positive instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.462647316646\n",
      "0.462647316646\n"
     ]
    }
   ],
   "source": [
    "print((TP) / (TP + FN))\n",
    "print(metrics.recall_score(train_data.Positive_Result, train_data.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity - *When the actual value is negative, how often is the prediction correct?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88033391787227822"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TN) / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives Rate - *When the actual value is negative, how often is the prediction incorrect?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11966608212772176"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision - *When a positive value is predicted, how often is the prediction correct?*\n",
    " * How precise the classifier is when selecting a positive instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5918634353\n",
      "0.5918634353\n"
     ]
    }
   ],
   "source": [
    "print(TP / (TP + FP))\n",
    "print(metrics.precision_score(train_data.Positive_Result, train_data.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.88      0.85     54744\n",
      "       True       0.59      0.46      0.52     20534\n",
      "\n",
      "avg / total       0.75      0.77      0.76     75278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(train_data['Positive_Result'], train_data['predicted'], target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = clf.predict_proba(train_data[scenarios[best_scenario]['predictors']])\n",
    "formatted = list()\n",
    "for pFalse,pTrue  in results:\n",
    "    formatted.append(pTrue)\n",
    "\n",
    "outcome = pd.Series(formatted, index=train_data.index)\n",
    "\n",
    "train_data['Outcome'] = outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(train_data.Positive_Result, outcome)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a57034be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label='AUC = %0.4f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.xlim([-0.1, 1.2])\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.xlabel('(1 - Specificity)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
