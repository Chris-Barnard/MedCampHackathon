{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chrisbarnard/Documents/Programming/Python/getting_started/MedCamp Hackathon/data\n"
     ]
    }
   ],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in data sources\n",
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTestData():\n",
    "    test_data = pd.read_csv('Test.csv',sep=',', parse_dates=[2], index_col=['Patient_ID', 'Health_Camp_ID'])\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTrainData():\n",
    "    train_data = pd.read_csv('Train/Train.csv',sep=',', parse_dates=[2], index_col=['Patient_ID', 'Health_Camp_ID'])\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in some other key fields\n",
    "### Define a function that will merge in all other fields into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getData(sourceData):\n",
    "    HC1 = pd.read_csv('Train/First_Health_Camp_Attended.csv', sep=',', index_col=['Patient_ID', 'Health_Camp_ID'])\n",
    "    HC1.pop('Unnamed: 4')\n",
    "    sourceData['Health_Camp_Score_1'] = HC1['Health_Score']\n",
    "    sourceData['Health_Camp_Attended_1'] = sourceData['Health_Camp_Score_1'].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "    HC2 = pd.read_csv('Train/Second_Health_Camp_Attended.csv', sep=',', index_col=['Patient_ID','Health_Camp_ID'])\n",
    "    sourceData['Health_Camp_Score_2'] = HC2['Health Score']\n",
    "    sourceData['Health_Camp_Attended_2'] = sourceData['Health_Camp_Score_2'].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "    HC3 = pd.read_csv('Train/Third_Health_Camp_Attended.csv', sep=',', index_col=['Patient_ID','Health_Camp_ID'])\n",
    "    sourceData['Health_Camp_Stalls_3'] = HC3['Number_of_stall_visited']\n",
    "    sourceData['Health_Camp_Attended_3'] = sourceData['Health_Camp_Stalls_3'].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "    ### Positive_Result\n",
    "\n",
    "    sourceData['Positive_Result'] = (sourceData['Health_Camp_Attended_1'] | sourceData['Health_Camp_Attended_2'] | sourceData['Health_Camp_Attended_3'])\n",
    "\n",
    "    ### Health_Camp_Details\n",
    "\n",
    "    HCDetails = pd.read_csv('Train/Health_Camp_Detail.csv', sep=',', index_col='Health_Camp_ID', parse_dates=[1,2])\n",
    "    sourceData = sourceData.join(HCDetails)\n",
    "\n",
    "    ### Patient Details\n",
    "\n",
    "    PatientProfiles = pd.read_csv('Train/Patient_Profile.csv', sep=',', index_col='Patient_ID', parse_dates=[8])\n",
    "    sourceData = sourceData.join(PatientProfiles)\n",
    "\n",
    "    ### Add in the reg_num\n",
    "\n",
    "    df = sourceData[['Registration_Date','Positive_Result']]\n",
    "    df.reset_index(level=['Patient_ID','Health_Camp_ID'], inplace=1)\n",
    "    hist = df.sort_values(by=['Patient_ID','Registration_Date'])\n",
    "    hist.set_index(['Patient_ID','Health_Camp_ID'], inplace=1)\n",
    "\n",
    "    sourceData['reg_num'] = hist.groupby(level=0).cumcount()\n",
    "    \n",
    "    ### Repeat Register Flag\n",
    "    sourceData['rep_reg'] = sourceData['reg_num'].apply(lambda x: True if x > 0 else False)\n",
    "    \n",
    "    ### rep_reg_bin\n",
    "\n",
    "    # define a bin size\n",
    "    size = 8\n",
    "    bins = np.logspace(np.log2(0.99), np.log2(sourceData.reg_num.max()), size, endpoint=True, base=2)\n",
    "\n",
    "    sourceData['rep_reg_bin'] = pd.cut(sourceData.reg_num, bins).cat.rename_categories([1,2,3,4,5,6,7])\n",
    "    sourceData['rep_reg_bin'] = sourceData['rep_reg_bin'].cat.add_categories(-1)\n",
    "    sourceData['rep_reg_bin'] = sourceData['rep_reg_bin'].fillna(-1)\n",
    "    \n",
    "    #train_data['rep_reg_bin'] = train_data['rep_reg_bin'].cat.rename_categories([1,2,3,4,5,6,7])\n",
    "    \n",
    "    ### has_var\n",
    "    sourceData['has_var'] = (sourceData['Var1'] > 0) | (sourceData['Var2'] > 0) | (sourceData['Var3'] > 0) | (sourceData['Var4'] > 0) | (sourceData['Var5'] > 0) \n",
    "    \n",
    "    ### v1_b\n",
    "    # define a bin size\n",
    "    #size = 5\n",
    "    #bins = np.logspace(np.log2(.99), np.log2(sourceData.Var1.max()), size, endpoint=True, base=2)\n",
    "\n",
    "    #sourceData['v1_b'] = pd.cut(sourceData.Var1, bins).cat.rename_categories([1,2,3,4])\n",
    "    #sourceData['v1_b'] = sourceData['v1_b'].cat.add_categories(-1)\n",
    "    #sourceData['v1_b'] = sourceData['v1_b'].fillna(-1)\n",
    "    \n",
    "    ### online   \n",
    "    sourceData['online'] = (sourceData['Online_Follower']) | (sourceData['LinkedIn_Shared']) | (sourceData['Twitter_Shared']) | (sourceData['Facebook_Shared'])\n",
    "    \n",
    "    ### City_Type\n",
    "    sourceData['City_Type'] = sourceData['City_Type'].fillna('Z')\n",
    "    \n",
    "    ### Age\n",
    "    val_counts = sourceData['Age'].value_counts().to_dict()\n",
    "    #mode_age = sourceData['Age'].mode()\n",
    "    for key, value in val_counts.items():\n",
    "        if key == 'None':\n",
    "            val_counts[key] = None\n",
    "        else:\n",
    "            val_counts[key] = int(key)\n",
    "    val_counts\n",
    "    sourceData['Age'] = sourceData['Age'].apply(lambda x: val_counts.get(x))\n",
    "    sourceData['Age'] = sourceData['Age'].fillna(41)\n",
    "    \n",
    "    ### Education_Score\n",
    "    val_counts = sourceData['Education_Score'].value_counts().to_dict()\n",
    "    for key, value in val_counts.items():\n",
    "        if key == 'None':\n",
    "            val_counts[key] = None\n",
    "        else:\n",
    "            val_counts[key] = float(key)\n",
    "    val_counts\n",
    "    sourceData['Education_Score'] = sourceData['Education_Score'].apply(lambda x: val_counts.get(x))\n",
    "    \n",
    "    ### Employer_Category\n",
    "    sourceData['Employer_Category'] = sourceData['Employer_Category'].fillna('None Provided')\n",
    "    \n",
    "    ### Time Since First Interaction\n",
    "    sourceData['DaysSeen'] = sourceData.Registration_Date - sourceData.First_Interaction\n",
    "\n",
    "    ### DaysSeen\n",
    "    sourceData.DaysSeen = sourceData[sourceData.DaysSeen.notnull()].DaysSeen.apply(lambda x: x.days)\n",
    "    sourceData.DaysSeen = sourceData.DaysSeen.fillna(0)\n",
    "\n",
    "    \n",
    "    return sourceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = getData(loadTrainData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### var1-5 train_data\n",
    "vars = ['Var3','Var4','Var5','Var1','Var2','Age','reg_num','DaysSeen']\n",
    "scaler = {}\n",
    "\n",
    "\n",
    "# bin data and store scale to apply to test_data\n",
    "### v1_b\n",
    "# define a bin size\n",
    "size = 5\n",
    "scaler['v1_b'] = np.logspace(np.log2(.99), np.log2(train_data.Var1.max()), size, endpoint=True, base=2)\n",
    "train_data['v1_b'] = pd.cut(train_data.Var1, scaler['v1_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['v1_b'] = train_data['v1_b'].cat.add_categories(-1)\n",
    "train_data['v1_b'] = train_data['v1_b'].fillna(-1)\n",
    "\n",
    "### v2_b\n",
    "# define a bin size\n",
    "size = 5\n",
    "scaler['v2_b'] = np.logspace(np.log2(.99), np.log2(train_data.Var2.max()), size, endpoint=True, base=2)\n",
    "train_data['v2_b'] = pd.cut(train_data.Var2, scaler['v2_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['v2_b'] = train_data['v2_b'].cat.add_categories(-1)\n",
    "train_data['v2_b'] = train_data['v2_b'].fillna(-1)\n",
    "\n",
    "### age_b\n",
    "size = 5\n",
    "scaler['age_b'] = np.linspace(0,train_data.Age.max(), size, endpoint=True)\n",
    "\n",
    "train_data['age_b'] = pd.cut(train_data.Age, scaler['age_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['age_b'] = train_data['age_b'].cat.add_categories(-1)\n",
    "train_data['age_b'] = train_data['age_b'].fillna(-1)\n",
    "\n",
    "### educ_b\n",
    "size = 5\n",
    "scaler['educ_b'] = np.linspace(0,train_data.Education_Score.max(), size, endpoint=True)\n",
    "\n",
    "train_data['educ_b'] = pd.cut(train_data.Age, scaler['educ_b']).cat.rename_categories([1,2,3,4])\n",
    "train_data['educ_b'] = train_data['educ_b'].cat.add_categories(-1)\n",
    "train_data['educ_b'] = train_data['educ_b'].fillna(-1)\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "\n",
    "for var in vars:\n",
    "    scaler[var] = scale.fit(train_data[var])\n",
    "    #x_minmax = scale.fit(train_data[var])\n",
    "    #print(x_minmax)\n",
    "    \n",
    "    train_data[var] = scaler[var].transform(train_data[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data = getData(loadTestData())\n",
    "drops = ['Health_Camp_Score_1','Health_Camp_Attended_1','Health_Camp_Score_2','Health_Camp_Attended_2','Health_Camp_Stalls_3','Health_Camp_Attended_3','Positive_Result']\n",
    "for col in drops:\n",
    "    test_data.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/chrisbarnard/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "### var1-5 test_data\n",
    "\n",
    "test_data['v1_b'] = pd.cut(test_data.Var1, scaler['v1_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['v1_b'] = test_data['v1_b'].cat.add_categories(-1)\n",
    "test_data['v1_b'] = test_data['v1_b'].fillna(-1)\n",
    "\n",
    "test_data['v2_b'] = pd.cut(test_data.Var2, scaler['v2_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['v2_b'] = test_data['v2_b'].cat.add_categories(-1)\n",
    "test_data['v2_b'] = test_data['v2_b'].fillna(-1)\n",
    "\n",
    "test_data['age_b'] = pd.cut(test_data.Age, scaler['age_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['age_b'] = test_data['age_b'].cat.add_categories(-1)\n",
    "test_data['age_b'] = test_data['age_b'].fillna(-1)\n",
    "\n",
    "test_data['educ_b'] = pd.cut(test_data.Age, scaler['educ_b']).cat.rename_categories([1,2,3,4])\n",
    "test_data['educ_b'] = test_data['educ_b'].cat.add_categories(-1)\n",
    "test_data['educ_b'] = test_data['educ_b'].fillna(-1)\n",
    "\n",
    "for var in vars:\n",
    "    test_data[var] = scaler[var].transform(test_data[var].reshape(-1,1)).reshape(1,-1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in main model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import models from scikit learn module:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import metrics\n",
    "\n",
    "#Generic function for making a classification model and accessing performance:\n",
    "def classification_model(model, data, predictors, outcome):\n",
    "    #Fit the model\n",
    "    model.fit(data[predictors],data[outcome])\n",
    "    \n",
    "    #Make predictions on training set:\n",
    "    predictions = model.predict(data[predictors])\n",
    "  \n",
    "    #Print accuracy\n",
    "    accuracy = metrics.accuracy_score(predictions,data[outcome])\n",
    "    print (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "    \n",
    "    # Record auc score\n",
    "    auc = metrics.roc_auc_score(data[outcome], predictions)\n",
    "    \n",
    "    print (\"ROC AUC Score : %s\" % \"{0:.3%}\".format(auc))\n",
    "\n",
    "    #Perform k-fold cross-validation with 5 folds\n",
    "    kf = KFold(data.shape[0], n_folds=5)\n",
    "    error = []\n",
    "    for train, test in kf:\n",
    "        # Filter training data\n",
    "        train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "        # The target we're using to train the algorithm.\n",
    "        train_target = data[outcome].iloc[train]\n",
    "    \n",
    "        # Training the algorithm using the predictors and target.\n",
    "        model.fit(train_predictors, train_target)\n",
    "    \n",
    "        #Record error from each cross-validation run\n",
    "        error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    " \n",
    "    print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "    #Fit the model again so that it can be refered outside the function:\n",
    "    model.fit(data[predictors],data[outcome])\n",
    "    \n",
    "    # return the roc_auc score to be stored\n",
    "    return model\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['Category1','Category2','Category3','rep_reg_bin','City_Type','age_b','educ_b','v1_b','v2_b','Employer_Category']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    train_data[i] = le.fit_transform(train_data[i])\n",
    "    #scaler[i] = scale.fit(train_data[i])\n",
    "    #train_data[i] = scaler[i].transform(train_data[i])\n",
    "#train_data.dtypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in var_mod:\n",
    "    test_data[i] = le.fit_transform(test_data[i])\n",
    "    #test_data[i] = scaler[i].transform(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Registration_Date</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Health_Camp_Score_1</th>\n",
       "      <th>Health_Camp_Attended_1</th>\n",
       "      <th>Health_Camp_Score_2</th>\n",
       "      <th>Health_Camp_Attended_2</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>rep_reg</th>\n",
       "      <th>rep_reg_bin</th>\n",
       "      <th>has_var</th>\n",
       "      <th>online</th>\n",
       "      <th>DaysSeen</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v2_b</th>\n",
       "      <th>age_b</th>\n",
       "      <th>educ_b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Health_Camp_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489652</th>\n",
       "      <th>6578</th>\n",
       "      <td>2005-09-10</td>\n",
       "      <td>0.420086</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>1.442928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.695679</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507246</th>\n",
       "      <th>6578</th>\n",
       "      <td>2005-08-18</td>\n",
       "      <td>5.795981</td>\n",
       "      <td>1.263127</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>5.561781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2.592913</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546566</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523729</th>\n",
       "      <th>6534</th>\n",
       "      <td>2006-04-29</td>\n",
       "      <td>-0.104391</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>-0.204613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.402054</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499368</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.772144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524931</th>\n",
       "      <th>6535</th>\n",
       "      <td>2004-02-07</td>\n",
       "      <td>-0.104391</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>-0.204613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696944</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521364</th>\n",
       "      <th>6529</th>\n",
       "      <td>2006-02-28</td>\n",
       "      <td>1.862400</td>\n",
       "      <td>0.201998</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>-0.11236</td>\n",
       "      <td>5.561781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845597</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4.088302</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2.857445</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Registration_Date      Var1      Var2      Var3  \\\n",
       "Patient_ID Health_Camp_ID                                                   \n",
       "489652     6578                  2005-09-10  0.420086 -0.063285 -0.019631   \n",
       "507246     6578                  2005-08-18  5.795981  1.263127 -0.019631   \n",
       "523729     6534                  2006-04-29 -0.104391 -0.063285 -0.019631   \n",
       "524931     6535                  2004-02-07 -0.104391 -0.063285 -0.019631   \n",
       "521364     6529                  2006-02-28  1.862400  0.201998 -0.019631   \n",
       "\n",
       "                              Var4      Var5  Health_Camp_Score_1  \\\n",
       "Patient_ID Health_Camp_ID                                           \n",
       "489652     6578           -0.11236  1.442928                  NaN   \n",
       "507246     6578           -0.11236  5.561781                  NaN   \n",
       "523729     6534           -0.11236 -0.204613                  NaN   \n",
       "524931     6535           -0.11236 -0.204613                  NaN   \n",
       "521364     6529           -0.11236  5.561781                  NaN   \n",
       "\n",
       "                          Health_Camp_Attended_1  Health_Camp_Score_2  \\\n",
       "Patient_ID Health_Camp_ID                                               \n",
       "489652     6578                            False                  NaN   \n",
       "507246     6578                            False                  NaN   \n",
       "523729     6534                            False             0.402054   \n",
       "524931     6535                            False                  NaN   \n",
       "521364     6529                            False             0.845597   \n",
       "\n",
       "                          Health_Camp_Attended_2   ...     reg_num rep_reg  \\\n",
       "Patient_ID Health_Camp_ID                          ...                       \n",
       "489652     6578                            False   ...    1.695679    True   \n",
       "507246     6578                            False   ...    2.592913    True   \n",
       "523729     6534                             True   ...    0.499368    True   \n",
       "524931     6535                            False   ...   -0.696944   False   \n",
       "521364     6529                             True   ...    4.088302    True   \n",
       "\n",
       "                          rep_reg_bin has_var online  DaysSeen  v1_b  v2_b  \\\n",
       "Patient_ID Health_Camp_ID                                                    \n",
       "489652     6578                     5    True      0  0.302927     1     0   \n",
       "507246     6578                     5    True      0  0.546566     3     2   \n",
       "523729     6534                     3   False      0  1.772144     0     0   \n",
       "524931     6535                     0   False      0 -0.723311     0     0   \n",
       "521364     6529                     6    True      1  2.857445     2     1   \n",
       "\n",
       "                           age_b  educ_b  \n",
       "Patient_ID Health_Camp_ID                 \n",
       "489652     6578                1       0  \n",
       "507246     6578                0       0  \n",
       "523729     6534                1       0  \n",
       "524931     6535                1       0  \n",
       "521364     6529                0       0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Registration_Date</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Camp_Start_Date</th>\n",
       "      <th>Camp_End_Date</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_num</th>\n",
       "      <th>rep_reg</th>\n",
       "      <th>rep_reg_bin</th>\n",
       "      <th>has_var</th>\n",
       "      <th>online</th>\n",
       "      <th>DaysSeen</th>\n",
       "      <th>v1_b</th>\n",
       "      <th>v2_b</th>\n",
       "      <th>age_b</th>\n",
       "      <th>educ_b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Health_Camp_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505701</th>\n",
       "      <th>6548</th>\n",
       "      <td>2006-05-21</td>\n",
       "      <td>-0.719619</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.715928</td>\n",
       "      <td>2006-06-13</td>\n",
       "      <td>2006-08-18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715928</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3.710182</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500633</th>\n",
       "      <th>6584</th>\n",
       "      <td>2006-06-02</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-08-04</td>\n",
       "      <td>2006-08-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719619</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.262717</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506945</th>\n",
       "      <th>6582</th>\n",
       "      <td>2006-08-10</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-04-06</td>\n",
       "      <td>2007-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.712236</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.306171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497447</th>\n",
       "      <th>6551</th>\n",
       "      <td>2006-08-27</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-11-13</td>\n",
       "      <td>2006-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.719619</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.715928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496446</th>\n",
       "      <th>6533</th>\n",
       "      <td>2006-09-19</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>2006-09-20</td>\n",
       "      <td>2006-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.723311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Registration_Date      Var1      Var2      Var3  \\\n",
       "Patient_ID Health_Camp_ID                                                   \n",
       "505701     6548                  2006-05-21 -0.719619 -0.723311 -0.723311   \n",
       "500633     6584                  2006-06-02 -0.723311 -0.723311 -0.723311   \n",
       "506945     6582                  2006-08-10 -0.723311 -0.723311 -0.723311   \n",
       "497447     6551                  2006-08-27 -0.723311 -0.723311 -0.723311   \n",
       "496446     6533                  2006-09-19 -0.723311 -0.723311 -0.723311   \n",
       "\n",
       "                               Var4      Var5 Camp_Start_Date Camp_End_Date  \\\n",
       "Patient_ID Health_Camp_ID                                                     \n",
       "505701     6548           -0.723311 -0.715928      2006-06-13    2006-08-18   \n",
       "500633     6584           -0.723311 -0.723311      2006-08-04    2006-08-09   \n",
       "506945     6582           -0.723311 -0.723311      2006-04-06    2007-11-07   \n",
       "497447     6551           -0.723311 -0.723311      2006-11-13    2006-11-18   \n",
       "496446     6533           -0.723311 -0.723311      2006-09-20    2006-09-23   \n",
       "\n",
       "                           Category1  Category2   ...     reg_num  rep_reg  \\\n",
       "Patient_ID Health_Camp_ID                         ...                        \n",
       "505701     6548                    2          5   ...   -0.715928     True   \n",
       "500633     6584                    1          0   ...   -0.719619     True   \n",
       "506945     6582                    0          4   ...   -0.712236     True   \n",
       "497447     6551                    1          2   ...   -0.719619     True   \n",
       "496446     6533                    0          3   ...   -0.723311    False   \n",
       "\n",
       "                           rep_reg_bin  has_var  online  DaysSeen  v1_b  v2_b  \\\n",
       "Patient_ID Health_Camp_ID                                                       \n",
       "505701     6548                      2     True       0  3.710182     1     0   \n",
       "500633     6584                      1    False       1  1.262717     0     0   \n",
       "506945     6582                      3    False       0 -0.306171     0     0   \n",
       "497447     6551                      1    False       0 -0.715928     0     0   \n",
       "496446     6533                      0    False       0 -0.723311     0     0   \n",
       "\n",
       "                          age_b  educ_b  \n",
       "Patient_ID Health_Camp_ID                \n",
       "505701     6548               1       0  \n",
       "500633     6584               1       0  \n",
       "506945     6582               1       0  \n",
       "497447     6551               1       0  \n",
       "496446     6533               1       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the model that we want to use and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   15.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=4)]: Done  75 out of  75 | elapsed:   21.3s finished\n"
     ]
    }
   ],
   "source": [
    "# I want to write a loop to test out a couple of different models and show the results\n",
    "# I need a variable to hold the scenarios to run - it will be a list of dicts describing each run\n",
    "outcome_var = 'Positive_Result'\n",
    "predictor_var1 = ['Category1','Category2','Category3','rep_reg_bin','City_Type','age_b','educ_b','online','v1_b','v2_b','Employer_Category']\n",
    "predictor_var2 = ['Category1','Category2','rep_reg_bin','City_Type','age_b','educ_b','online','v1_b','v2_b','has_var','Employer_Category']\n",
    "predictor_var3 = ['DaysSeen','Category1','Category2','Category3','reg_num','rep_reg','City_Type','Age','educ_b','online','has_var','Employer_Category']\n",
    "predictor_var4 = ['DaysSeen','Category1','Category2','Category3','rep_reg','reg_num','City_Type','Age','educ_b','online','Var1','Var2','Var3','Var4','Var5','Employer_Category']\n",
    "predictor_var5 = ['Category1','Category2','Category3','rep_reg','reg_num','City_Type','Age','educ_b','online','Var1','Var2','Var3','Var4','Var5','has_var','Employer_Category']\n",
    "predictor_var6 = ['DaysSeen','Category1','Category2','Category3','rep_reg','reg_num','City_Type','Age','educ_b','online','Var1','Var2','Var3','Var4','Var5','has_var','Employer_Category']\n",
    "scenarios = []\n",
    "scores = []\n",
    "\n",
    "# define scenarios I want to run\n",
    "\n",
    "### LinearSVC\n",
    "# Setup paramaters to search for this scenario\n",
    "c_values = list(np.logspace(np.log2(0.0001),np.log2(.05),25, base=2))\n",
    "penalty = ['l2']\n",
    "loss = ['squared_hinge']\n",
    "param_grid = dict(C=c_values, penalty=penalty, loss=loss)\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var1, params=param_grid))\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var2, params=param_grid))\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var3, params=param_grid))\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var4, params=param_grid))\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var5, params=param_grid))\n",
    "scenarios.append(dict(model=LinearSVC(tol=.000001, max_iter=1500, dual=False), predictors=predictor_var6, params=param_grid))\n",
    "\n",
    "### RBF SVC\n",
    "c_values = list(np.logspace(np.log2(0.01),np.log2(10),10, base=2))\n",
    "kernel= ['linear','poly','rbf','sigmoid']\n",
    "param_grid = dict(C=c_values)\n",
    "#scenarios.append(dict(model=SVC(), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "### LogisticRegression\n",
    "# Setup paramaters to search for this scenario\n",
    "c_values = list(np.logspace(np.log2(0.001),np.log2(.05),25, base=2))\n",
    "solver_options = ['newton-cg','lbfgs','sag','liblinear']\n",
    "param_grid = dict(C=c_values, solver=solver_options)\n",
    "#scenarios.append(dict(model=LogisticRegression(), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "### DecisionTree\n",
    "criterion = ['gini','entropy']\n",
    "max_features = [None, 1, 2, 4, 6]\n",
    "max_depth = [None, 4, 6, 8]\n",
    "param_grid = dict(criterion=criterion, max_features=max_features, max_depth=max_depth)\n",
    "#scenarios.append(dict(model=DecisionTreeClassifier(), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "### Random Forest\n",
    "param_grid = {}\n",
    "#scenarios.append(dict(model=RandomForestClassifier(n_estimators=100), predictors=predictor_var, params=param_grid))\n",
    "\n",
    "# second run\n",
    "n_estimators = [10, 20, 35, 50, 75]\n",
    "max_depth = [None, 4, 8, 12]\n",
    "max_features = [None, 1, 2, 4]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "predictors = ['Category1', 'Category2', 'Employer_Category', 'rep_reg_bin', 'City_Type'] #top 5 inserted from below\n",
    "#scenarios.append(dict(model=RandomForestClassifier(n_estimators=25), predictors=predictors, params=param_grid))\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# iterate through them\n",
    "for scenario in scenarios:\n",
    "    #classification_model(scenario['model'], train_data, scenario['predictors'], outcome_var)\n",
    "    #score = metrics.roc_auc_score(train_data[outcome_var], scenario['model'].predict(train_data[scenario['predictors']]))\n",
    "\n",
    "    grid = GridSearchCV(scenario['model'], param_grid=scenario['params'], cv=None, scoring='precision', verbose=1, n_jobs=4)\n",
    "    grid.fit(train_data[scenario['predictors']],train_data.Positive_Result)\n",
    "    scenario['model'] = grid.best_estimator_\n",
    "    predictions = scenario['model'].predict(train_data[scenario['predictors']])\n",
    "    score = metrics.precision_score(train_data.Positive_Result, predictions)\n",
    "    scores.append(score)\n",
    "\n",
    "### Include a final run of \n",
    "# Grab Feature Importance Table\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5975578406169666,\n",
       " 0.59588953932298294,\n",
       " 0.59198803812846557,\n",
       " 0.59069249334736063,\n",
       " 0.59314896291640473,\n",
       " 0.59190031152647971]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select model with the best auc score\n",
    "best_scenario = scores.index(max(scores))\n",
    "scenarios[best_scenario]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Category1',\n",
       " 'Category2',\n",
       " 'Category3',\n",
       " 'rep_reg_bin',\n",
       " 'City_Type',\n",
       " 'age_b',\n",
       " 'educ_b',\n",
       " 'online',\n",
       " 'v1_b',\n",
       " 'v2_b',\n",
       " 'Employer_Category']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios[best_scenario]['predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 76.755%\n",
      "ROC AUC Score : 66.921%\n",
      "Cross-Validation Score : 76.725%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.038593389345594968, class_weight=None, dual=False,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1500, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=1e-06, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the parameters we want to run\n",
    "#scenarios[best_scenario]['model'].set_params(**grid.best_params_)\n",
    "    \n",
    "\n",
    "# Run the model\n",
    "classification_model(scenarios[best_scenario]['model'], train_data, scenarios[best_scenario]['predictors'], outcome_var)\n",
    "\n",
    "# Save the predicted labels to the dataset\n",
    "train_data['predicted'] = scenarios[best_scenario]['model'].predict(train_data[scenarios[best_scenario]['predictors']])\n",
    "\n",
    "# Output the model used\n",
    "scenarios[best_scenario]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Version for LinearSVC\n",
    "clf = CalibratedClassifierCV(scenarios[best_scenario]['model'])\n",
    "clf.fit(train_data[scenarios[best_scenario]['predictors']],train_data[outcome_var])\n",
    "results = clf.predict_proba(test_data[scenarios[best_scenario]['predictors']])\n",
    "formatted = list()\n",
    "for pFalse,pTrue  in results:\n",
    "    formatted.append(pTrue)\n",
    "\n",
    "outcome = pd.Series(formatted, index=test_data.index)\n",
    "\n",
    "test_data['Outcome'] = outcome\n",
    "test_data['Outcome'].to_csv('output.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into results\n",
    "## What values do we miss on the training sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.727224\n",
       "Name: Positive_Result, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null accuracy for the problem\n",
    "train_data.Positive_Result.value_counts().head(1) / len(train_data.Positive_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive_Result</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>48482</td>\n",
       "      <td>6262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>11236</td>\n",
       "      <td>9298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted        False  True \n",
       "Positive_Result              \n",
       "False            48482   6262\n",
       "True             11236   9298"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "train_data.groupby(['predicted','Positive_Result']).size().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(train_data.Positive_Result, train_data.predicted)\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy - *How often is the classifier correct?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767554929727\n",
      "0.767554929727\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / (FP + FN + TP + TN))\n",
    "print(metrics.accuracy_score(train_data.Positive_Result, train_data.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity - *When the actual value is positive, how often is the prediction correct?*\n",
    " * How 'sensitive' or selective is the model with detecting a positive instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.452809973702\n",
      "0.452809973702\n"
     ]
    }
   ],
   "source": [
    "print((TP) / (TP + FN))\n",
    "print(metrics.recall_score(train_data.Positive_Result, train_data.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity - *When the actual value is negative, how often is the prediction correct?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88561303521847146"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TN) / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives Rate - *When the actual value is negative, how often is the prediction incorrect?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11438696478152857"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision - *When a positive value is predicted, how often is the prediction correct?*\n",
    " * How precise the classifier is when selecting a positive instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597557840617\n",
      "0.597557840617\n"
     ]
    }
   ],
   "source": [
    "print(TP / (TP + FP))\n",
    "print(metrics.precision_score(train_data.Positive_Result, train_data.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.89      0.85     54744\n",
      "       True       0.60      0.45      0.52     20534\n",
      "\n",
      "avg / total       0.75      0.77      0.76     75278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(train_data['Positive_Result'], train_data['predicted'], target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
